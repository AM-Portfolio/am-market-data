# Spring Configuration
spring:  
  data:
    mongodb:
      uri: ${MONGODB_URL}
      database: ${MONGODB_DATABASE}
      username: ${MONGODB_USERNAME}
      password: ${MONGODB_PASSWORD}
      authentication-database: admin
      # Pre-production specific MongoDB settings
      auto-index-creation: true
      connect-timeout: 5000
      socket-timeout: 10000
      max-connection-idle-time: 60000
      max-connection-life-time: 300000
      
    # Redis Configuration for Pre-production
    redis:
      host: ${REDIS_HOSTNAME}
      password: ${REDIS_PASSWORD}
      port: ${REDIS_PORT}
      # Pre-production specific Redis settings
      timeout: 5000
      connect-timeout: 5000
      client-name: market-data-preprod
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 2
          max-wait: 2000
  
  # Kafka Configuration for Pre-production
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}
    consumer:
      group-id: ${KAFKA_CONSUMER_GROUP_ID}
      auto-offset-reset: ${KAFKA_CONSUMER_AUTO_OFFSET_RESET}
      # Pre-production specific Kafka consumer settings
      max-poll-records: 500
      fetch-max-wait: 500
      fetch-min-size: 1
      heartbeat-interval: 3000
      session-timeout: 30000
    producer:
      # Pre-production specific Kafka producer settings
      retries: 3
      batch-size: 16384
      buffer-memory: 33554432
      acks: all
      compression-type: snappy
    properties:
      request.timeout.ms: 30000
      max.block.ms: 60000

# # InfluxDB Configuration for Pre-production
# influx:
#   url: ${INFLUXDB_URL}
#   token: ${INFLUXDB_TOKEN}
#   org: ${INFLUXDB_ORG}
#   bucket: ${INFLUXDB_BUCKET}
#   # Pre-production specific InfluxDB settings
#   connection-timeout: 10000
#   write-timeout: 10000
#   read-timeout: 10000
#   gzip-enabled: true

# Market Data Processing Configuration for Pre-production
market-data:
  thread-pool-size: ${MARKET_DATA_THREAD_POOL_SIZE:5}
  thread-queue-capacity: ${MARKET_DATA_THREAD_QUEUE_CAPACITY:10}
  max-retries: ${MARKET_DATA_MAX_RETRIES:3}
  retry-delay-ms: ${MARKET_DATA_RETRY_DELAY_MS:1000}
  max-age-minutes: ${MARKET_DATA_MAX_AGE_MINUTES:15}
  # Pre-production specific processing settings
  validation:
    strict-mode: true
    timeout-seconds: 30
  scheduler:
    cookie-refresh: "0 */30 * * * *"  # Every 30 minutes
    indices-fetch: "15 */2 9-15 * * MON-FRI"  # Every 2 minutes during trading hours
    etf-fetch: "45 */2 9-15 * * MON-FRI"  # Every 2 minutes during trading hours
    timezone: "Asia/Kolkata"

# Upstox Configuration for Pre-production
upstox:
  interval: I1
  auth:
    base-url: ${UPSTOX_API_BASE_URL}
    code: ${UPSTOX_CODE}
    api-key: ${UPSTOX_API_KEY}
    secret-key: ${UPSTOX_SECRET_KEY}
    access-token: ${UPSTOX_ACCESS_TOKEN}
    redirect-uri: ${UPSTOX_REDIRECT_URI}
    authorization-url: https://api-v2.upstox.com/login/authorization/dialog
    token-url: https://api-v2.upstox.com/login/authorization/token
    token-refresh-interval: 3600000
    scope: orders feed portfolio

# Zerodha Configuration for Pre-production
zerodha:
  api:
    key: ${ZERODHA_API_KEY}
    secret: ${ZERODHA_API_SECRET}
    access-token: ${ZERODHA_API_ACCESS_TOKEN}
    refresh-token: ${ZERODHA_API_REFRESH_TOKEN}
    base-url: https://api.kite.trade
    login-url: https://kite.zerodha.com/connect/login
    # Pre-production specific Zerodha settings
    timeout: 10000
    retry-count: 3
    retry-delay-ms: 1000

# Actuator Configuration for Pre-production
# management:
#   endpoints:
#     web:
#       exposure:
#         include: health,info,metrics,prometheus
#       base-path: /actuator
#   endpoint:
#     health:
#       show-details: always
#       group:
#         readiness:
#           include: mongo,redis,kafka,diskSpace
#         liveness:
#           include: ping,diskSpace
#       probes:
#         enabled: true
#   metrics:
#     tags:
#       application: market-data-preprod
#       environment: preprod
#     export:
#       prometheus:
#         enabled: true
#   info:
#     env:
#       enabled: true
#     java:
#       enabled: true
#     build:
#       enabled: true

# Logging Configuration for Pre-production
logging:
  level:
    root: INFO
    '[com.am.marketdata]': INFO
    '[com.am.marketdata.scheduler]': INFO
    '[com.am.marketdata.service]': INFO
    '[com.am.marketdata.external.api]': INFO
    '[org.springframework.data.mongodb]': WARN
    '[org.springframework.kafka]': WARN
    '[org.apache.kafka]': WARN
  pattern:
    console: '{"timestamp":"%d{yyyy-MM-dd HH:mm:ss.SSS}","level":"%p","thread":"%t","class":"%c","message":"%m"}%n'
    file: '{"timestamp":"%d{yyyy-MM-dd HH:mm:ss.SSS}","level":"%p","thread":"%t","class":"%c","message":"%m"}%n'
  file:
    name: logs/market-data-preprod.log
    max-size: 10MB
    max-history: 7

# Feature Flags for Pre-production
feature:
  stock-data-scheduler: true
  nse-scraper-scheduler: true
  parallel-processing: true
  cache-enabled: true
  metrics-enabled: true
  validation-enabled: true

# Server Configuration for Pre-production
server:
  port: 8084
  shutdown: graceful
  tomcat:
    max-threads: 200
    min-spare-threads: 20
    max-connections: 8192
    connection-timeout: 20000
    accept-count: 100
    max-swallow-size: 2MB
    max-http-form-post-size: 2MB
